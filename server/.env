# Watsonx.ai LLM Configuration
WATSONX_API_URL=https://api.watsonx.ai/v1/text/generation
WATSONX_API_KEY=your_watsonx_api_key_here
WATSONX_PROJECT_ID=your_project_id_here
WATSONX_MODEL_ID=meta-llama/llama-2-70b-chat

# Server Configuration
PORT=3001
NODE_ENV=development

# CORS Configuration (if needed)
CORS_ORIGIN=http://localhost:5173

# Rate Limiting
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100

# Logging
LOG_LEVEL=info

# Security
JWT_SECRET=your_jwt_secret_here
API_KEY_HEADER=X-API-Key

# Watsonx.ai Advanced Configuration
WATSONX_MAX_TOKENS=4096
WATSONX_TEMPERATURE=0.1
WATSONX_TOP_P=0.9
WATSONX_REPETITION_PENTS=1.1

# Evaluation Configuration
EVALUATION_TIMEOUT_MS=30000
MAX_SECTIONS_PER_REQUEST=10
MAX_CONTENT_LENGTH=50000
